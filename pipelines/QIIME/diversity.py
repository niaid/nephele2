#!/usr/bin/python3

import os
import random
import string
import multiprocessing

from nephele2.pipelines.pipebase import PipeBase
import nephele2.pipelines.pipeline_error

class diversity(PipeBase):
    """
    This script plugs several QIIME diversity analyses together to form a basic workflow
    beginning with a BIOM table, mapping file, and optional phylogenetic tree.

    The included scripts are those run by the workflow scripts:
        alpha_rarefaction.py
        beta_diversity_through_plots.py
        summarize_taxa_through_plots.py
    plus the (non-workflow) scripts:
        make_distance_boxplots.py
        compare_alpha_diversity.py
        group_significance.py
    To update parameters to the workflow scripts, you should pass the same parameters file
    that you would pass if calling the workflow script directly.

    Additionally, a table summary is generated by running the ‘biom summarize-table’
    command (part of the biom-format package). To update parameters to this command, your
    parameters file should use ‘biom-summarize-table’ (without quotes) as the script name.
    """
    out_dir = "core_diversity"
    core_param = [
        "make_distance_boxplots:num_permutations\t0",
        "summarize_taxa:level\t2,3,4,5,6,7",
        "summarize_taxa:absolute_abundance\tTrue",
        "make_distance_boxplots:num_permutations\t0"]

    def __init__(self, log_info, map_file, in_d = "inputs", out_d = "outputs"):
        self.log_info = log_info
        self.map_file = map_file    # mapping file
        self.in_dir = in_d
        self.out_dir = out_d
        self.output = {}
        self.cmds = []
        mt = list()

        with open(self.map_file, "r") as f:
            r = [i.strip() for i in f.readlines()]

        for h in (r.pop(0)).split("\t"):
            if h in ["#SampleID", "BarcodeSequence", "LinkerPrimerSequence",
                "ForwardFastqFile", "ReverseFastqFile", "Description"]:
                continue
            else:
                mt.append("%s" % h.strip())

        self.meta_data = ",".join(mt)

    def param_file(self, p):
        pf = os.path.join(self.out_dir, "%s.txt" % "".join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)))
        with open(pf, "w") as f:
            f.write("\n".join(p + [""]))
        return(pf)

    def get_cmds(self):
        return(self.cmds)

    def get_output(self):
        self.output.update(self.scan_dir(os.path.join(self.out_dir, diversity.out_dir)))
        return(self.output)

    # run open reference otu picking
    # required: biom file and tree
    #
    # open reference:
    # run("otu_table_mc2_w_tax_no_pynast_failures.biom", "rep_set.tre")
    #
    # closed refernece:
    # run("otu_table.biom", "Greengenes_99/99_otus.tree")
    #
    # de novo:
    # run("otu_table.biom", "rep_set.tre")
    def run(self, depth, biom, tree = "", param = ["alpha_diversity:metrics\tobserved_species,chao1,PD_whole_tree,shannon"]):
        """
        core_diversity_analyses.py
            --output_dir=core_diversity
            --input_biom_fp=otus/otu_table_mc2_w_tax_no_pynast_failures.biom
            --mapping_fp=nephele_mapping.csv
            --sampling_depth=13030
            --categories=TreatmentGroup,BarcodeID,Sex,Cages,Experiment,Day,Antibiotics,Grouping_1,Grouping_2
            --tree_fp=otus/rep_set.tre
            --parameter_fp=otus_params.txt
            --parallel
            --jobs_to_start
        """
        for x in self.meta_data.split(","):
            cmd = "core_diversity_analyses.py -i \"%s\" -o \"%s\" -m \"%s\" -e %d -p \"%s\" -c \"%s\" %s -a -O %d --suppress_taxa_summary" % (
                biom, os.path.join(self.out_dir, diversity.out_dir, x), # output directory, absolute path
                self.map_file, depth,                                   # mapping file, sampling depth
                self.param_file(diversity.core_param + param), x,       # parameter file and metadata for diversity
                " -t \"%s\"" % tree if len(tree) > 0 else "--nonphylogenetic_diversity",
                multiprocessing.cpu_count())
            self.cmds.append(cmd)
            self.log_info(cmd)
            self.exec_cmnd(cmd)
        return(True)
